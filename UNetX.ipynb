{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UNetX.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nu7jMmWOkCsV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-KOOmZCkcNy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define functions.\n",
        "\n",
        "# 1x1 convolution, padding = 0.\n",
        "def con1x1_0(inCha, outCha, kernel_size=1, stride=1, bias=True):  # padding 0 by default.\n",
        "    return nn.Conv2d(inCha, outCha, kernel_size=kernel_size, stride=stride, bias=bias)\n",
        "\n",
        "\n",
        "# 3x3 convolution, padding = 0.\n",
        "def con3x3_0(inCha, outCha, kernel_size=3, stride=1, bias=True):\n",
        "    return nn.Conv2d(inCha, outCha, kernel_size=kernel_size, stride=stride, bias=bias)\n",
        "\n",
        "\n",
        "# 3x3 convolution with padding = 1.\n",
        "def con3x3_1(inCha, outCha, kernel_size=3, stride=1, padding=1, bias=True):\n",
        "    return nn.Conv2d(inCha, outCha, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias)\n",
        "\n",
        "\n",
        "# 2x2 transposed convolution.\n",
        "def traCon2x2(inCha, outCha, kernel_size, stride, padding, output_padding, bias=True):\n",
        "    return nn.ConvTranspose2d(inCha, outCha, kernel_size=kernel_size, stride=stride, padding=padding, output_padding=output_padding, bias=bias)\n",
        "\n",
        "\n",
        "# ReLU Activation function.\n",
        "def actReLU():\n",
        "    return nn.ReLU(inplace=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4KveIiYN1th",
        "colab_type": "text"
      },
      "source": [
        "\\\\\n",
        "### Class building one block of the encoding branch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgP4vA2xNuDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Build one block of the encoding branch.\n",
        "    Parameters\n",
        "    ----------\n",
        "    inCha : integer\n",
        "        Input channels for the convolution.\n",
        "    outCha : integer\n",
        "        Output channels of the convolution (number of kernels).\n",
        "    pooling : bool\n",
        "        Whether to perform the pooling or not at the end of the block.\n",
        "    poolPad : tuple of two integers\n",
        "        Padding to be used in the pooling.\n",
        "    Methods\n",
        "    -------\n",
        "    forward : forward pass into the block\n",
        "    \"\"\"\n",
        "    def __init__(self, inCha, outCha, pooling, poolPad):\n",
        "        super(EncBlock, self).__init__()\n",
        "\n",
        "        self.pooling = pooling\n",
        "\n",
        "        self.con0 = con3x3_1(inCha, outCha)\n",
        "        self.con1 = con3x3_1(outCha, outCha)\n",
        "\n",
        "        self.act = actReLU()\n",
        "\n",
        "        if self.pooling:\n",
        "            self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=poolPad)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Perform the forward pass through the block.\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : torch tensor\n",
        "            4D tensor, output of the block.\n",
        "                first dimension = batch size\n",
        "                second dimension = number of channels\n",
        "                third dimension = number of columns\n",
        "                fourth dimension = number of rows\n",
        "        Returns\n",
        "        -------\n",
        "        x : torch tensor\n",
        "            4D tensor output by the block.\n",
        "              first dimension = batch size\n",
        "              second dimension = number of channels\n",
        "              third dimension = number of columns\n",
        "              fourth dimension = number of rows\n",
        "        x_0 : torch tensor\n",
        "            4D tensor output by the block before pooling. Dimensions as above.\n",
        "        \"\"\"\n",
        "        x = self.act(self.con0(x))\n",
        "        x = self.act(self.con1(x))\n",
        "        xOut = x\n",
        "        if self.pooling:\n",
        "            x = self.pool(x)\n",
        "\n",
        "        # print(\"\\n EncBlock Output Shape = \", x.shape)\n",
        "\n",
        "        return x, xOut\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rq5Bl4D8S15x",
        "colab_type": "text"
      },
      "source": [
        "\\\\\n",
        "### Class bulding one block of the decoding branch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr_B8Tk3_QsA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Block of the decoding path.\n",
        "    Parameters\n",
        "    ----------\n",
        "    inCha : integer\n",
        "        Input channels for the convolution.\n",
        "    outCha : integer\n",
        "        Output channels of the convolution (number of kernels).\n",
        "    tranPad : tuple of two intergers\n",
        "        Padding to be used in the transposed convolution.\n",
        "    finConv : bool\n",
        "        Define whether to do the last 1x1 convolution or not.\n",
        "    Methods\n",
        "    -------\n",
        "    forward : forward pass into the block\n",
        "    \"\"\"\n",
        "    def __init__(self, inCha, outCha, tranPad, finConv=False, finOutCha=1):\n",
        "        super(DecBlock, self).__init__()\n",
        "\n",
        "        self.traCon = traCon2x2(inCha, outCha, kernel_size=2, stride=2,\n",
        "                                padding=tranPad, output_padding=(0, 0))\n",
        "        self.con0 = con3x3_1(2*outCha, outCha)\n",
        "        self.con1 = con3x3_1(outCha, outCha)\n",
        "\n",
        "        self.act = actReLU()\n",
        "\n",
        "        self.finConv = finConv\n",
        "        if self.finConv:\n",
        "            self.con2 = con1x1_0(outCha, finOutCha)\n",
        "\n",
        "    def forward(self, xDown, x):\n",
        "        \"\"\"\n",
        "        Perform the forward pass through the block.\n",
        "        Parameters\n",
        "        ----------\n",
        "        xDown : torch tensor\n",
        "            4D tensor generated by the corresding block in the\n",
        "            downsampling path.\n",
        "              first dimension = batch size\n",
        "              second dimension = number of channels\n",
        "              third dimension = number of columns\n",
        "              fourth dimension = number of rows\n",
        "        x : torch tensor\n",
        "            4D tensor, output of the block.\n",
        "              first dimension = batch size\n",
        "              second dimension = number of channels\n",
        "              third dimension = number of columns\n",
        "              fourth dimension = number of rows\n",
        "        Returns\n",
        "        -------\n",
        "        x : torch tensor\n",
        "            4D tensor output by the block.\n",
        "              first dimension = batch size\n",
        "              second dimension = number of channels\n",
        "              third dimension = number of columns\n",
        "              fourth dimension = number of rows\n",
        "        \"\"\"\n",
        "        xUp = self.traCon(x)\n",
        "        x = torch.cat((xUp, xDown), 1)\n",
        "\n",
        "        x = self.act((self.con0(x)))\n",
        "        x = self.act((self.con1(x)))\n",
        "\n",
        "        if self.finConv:\n",
        "            x = self.con2(x)\n",
        "\n",
        "        # print(\"\\n     DecBlock Output Shape = \", x.shape)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3E65_1dFAYNg",
        "colab_type": "text"
      },
      "source": [
        "\\\\\n",
        "### Class builing the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-9y-dIDAcwJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class UNetX(nn.Module):\n",
        "    \"\"\"\n",
        "    The network consists of an encoding branch followed by a decoding one.\n",
        "    Each block is made by blocks performing 2 convolutions each.\n",
        "    The last block of the decoder also performs a 1x1 convolution.\n",
        "    Parameters\n",
        "    ----------\n",
        "    inCha : integer\n",
        "        Number of channels in the input tensor.\n",
        "    finOutCha : integer\n",
        "        Number of channels of the network output.\n",
        "    depths : list of integer\n",
        "        First number is the number of input channels.\n",
        "        The remaining numbers give the number of kernels used\n",
        "        in the convolutions performed in the downsampling and\n",
        "        upsampling paths.\n",
        "        The length of this list, minus one,\n",
        "        gives the number of downsampling blocks.\n",
        "        The number of Upsampling blocks is len(depths)-2.\n",
        "    inWidth : integer\n",
        "        Number of columns of the input image.\n",
        "    inHeight : integer\n",
        "        Number of rows of the input image.\n",
        "    Methods\n",
        "    -------\n",
        "    forward : forward pass into the network\n",
        "    \"\"\"\n",
        "    def __init__(self, inCha, finOutCha, depths, inWidth, inHeight):\n",
        "        super(UNetX, self).__init__()\n",
        "\n",
        "        # If input height and/or width are odd, the input has been padded.\n",
        "        # Correct the input width and heigth.\n",
        "        if inWidth % 2 != 0:\n",
        "            inWidth += 1\n",
        "        if inHeight % 2 != 0:\n",
        "            inHeight += 1\n",
        "\n",
        "        # Adapt the list depths.\n",
        "        depths.insert(0, inCha)\n",
        "        self.depths = depths\n",
        "\n",
        "        self.down_convs = []\n",
        "        self.up_convs = []\n",
        "\n",
        "        # Build the encoder.\n",
        "        List_0 = [inWidth]\n",
        "        List_1 = [inHeight]\n",
        "        numDowns = len(depths)-1  # number of downsampling blocks\n",
        "        pad0 = 0\n",
        "        pad1 = 0\n",
        "        for i in range(numDowns):\n",
        "            pooling = True if i < numDowns-1 else False\n",
        "            # avoid odd num. using padding.\n",
        "            if (pooling and i < numDowns - 2):\n",
        "                if (inWidth/2) % 2 == 0:\n",
        "                    pad0 = 0\n",
        "                    inWidth //= 2\n",
        "                    List_0.append(inWidth)\n",
        "                else:\n",
        "                    pad0 = 1\n",
        "                    inWidth = inWidth // 2 + 1\n",
        "                    List_0.append(inWidth)\n",
        "                if (inHeight/2) % 2 == 0:\n",
        "                    pad1 = 0\n",
        "                    inHeight //= 2\n",
        "                    List_1.append(inHeight)\n",
        "                else:\n",
        "                    pad1 = 1\n",
        "                    inHeight = inHeight // 2 + 1\n",
        "                    List_1.append(inHeight)\n",
        "            # do not avoid odd numbers at the bottom.\n",
        "            if (pooling and i == numDowns - 2):\n",
        "                pad0 = 0\n",
        "                inWidth //= 2\n",
        "                List_0.append(inWidth)\n",
        "                pad1 = 0\n",
        "                inHeight //= 2\n",
        "                List_1.append(inHeight)\n",
        "            block = EncBlock(depths[i], depths[i+1], pooling, (pad0, pad1))\n",
        "            self.down_convs.append(block)\n",
        "\n",
        "        # Build the decoder.\n",
        "        List_0.reverse()\n",
        "        List_1.reverse()\n",
        "        numUps = len(depths) - 2  # number of upsampling blocks\n",
        "        self.depths.reverse()  # reverse the list of the depths\n",
        "        for i in range(numUps):\n",
        "            if List_0[i]*2 == List_0[i+1]:\n",
        "                pad0 = 0\n",
        "            else:\n",
        "                pad0 = 1\n",
        "            if List_1[i]*2 == List_1[i+1]:\n",
        "                pad1 = 0\n",
        "            else:\n",
        "                pad1 = 1\n",
        "            if i < (numUps - 1):\n",
        "                block = DecBlock(depths[i], depths[i+1], (pad0, pad1))\n",
        "                self.up_convs.append(block)\n",
        "            else:\n",
        "                block = DecBlock(depths[i], depths[i+1], (pad0, pad1),\n",
        "                                finConv=True, finOutCha=finOutCha)\n",
        "                self.up_convs.append(block)\n",
        "\n",
        "        self.down_convs = nn.ModuleList(self.down_convs)\n",
        "        self.up_convs = nn.ModuleList(self.up_convs)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Perform the forward pass through the network.\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : torch tensor\n",
        "            4D tensor defining input to be fed into the network.\n",
        "                first dimension = batch size\n",
        "                second dimension = number of channels\n",
        "                third dimension = number of columns of the input image\n",
        "                fourth dimension = Number of rows of the input image\n",
        "        Returns\n",
        "        -------\n",
        "        x : torch tensor\n",
        "            4D tensor output by the network.\n",
        "                first dimension = batch size\n",
        "                second dimension = number of channels\n",
        "                third dimension = number of columns of the target\n",
        "                fourth dimension = number of rows of the target\n",
        "        \"\"\"\n",
        "        encoder_outs = []\n",
        "\n",
        "        # If input height and/or width are odd, make it even (pad it).\n",
        "        padIt = False\n",
        "        pad3 = 0\n",
        "        pad2 = 0\n",
        "\n",
        "        if x.shape[3] % 2 != 0:\n",
        "            padIt = True\n",
        "            pad3 = 1\n",
        "        if x.shape[2] % 2 != 0:\n",
        "            padIt = True\n",
        "            pad2 = 1\n",
        "        if padIt:\n",
        "            p2d = (0, pad3, 0, pad2)\n",
        "            x = nn.functional.pad(x, p2d, 'constant', 0)\n",
        "\n",
        "        # Encoder.\n",
        "        for i, module in enumerate(self.down_convs):\n",
        "            x, x_0 = module(x)\n",
        "            encoder_outs.append(x_0)\n",
        "\n",
        "        # Decoder.\n",
        "        encoder_outs.reverse()\n",
        "        for i, module in enumerate(self.up_convs):\n",
        "            x_0 = encoder_outs[i+1]\n",
        "            x = module(x_0, x)\n",
        "\n",
        "        # If the input has been padded, crop the output.\n",
        "        if padIt:\n",
        "            x = x[:, :, 0:(x.shape[2]-pad2), 0:(x.shape[3]-pad3)]\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-y-l21lBKWf",
        "colab_type": "text"
      },
      "source": [
        "\\\\\n",
        "### Network sanity check."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxelL9QY-sn8",
        "colab_type": "code",
        "outputId": "0e45c1c7-a8cc-4ce5-9549-cc91bef2e6ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "inpCha = 5\n",
        "outCha = 1\n",
        "lstKer = [64, 64, 64, 128, 32]\n",
        "inpWidth = 100\n",
        "inpHeight = 100\n",
        "#kerSiz = 3\n",
        "#conPad = 0\n",
        "\n",
        "x = torch.randn([1, inpCha, inpWidth, inpHeight])\n",
        "\n",
        "model = UNetX(inpCha, outCha, lstKer, inpWidth, inpHeight)\n",
        "#print(model)\n",
        "\n",
        "print(\"\\n\", x.shape)\n",
        "x = model(x)\n",
        "print(x.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " torch.Size([1, 5, 100, 100])\n",
            "torch.Size([1, 1, 100, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}